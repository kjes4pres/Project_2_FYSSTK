{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebabd74",
   "metadata": {},
   "source": [
    "# Part d) Testing different activation functions and depths of the neural network\n",
    "\n",
    "You should also test different activation functions for the hidden layers. Try out the Sigmoid, the RELU and the Leaky RELU functions and discuss your results. Test your results as functions of the number of hidden layers and nodes. Do you see signs of overfitting? It is optional in this project to perform a bias-variance trade-off analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05980ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "mplstyle.use([\"ggplot\", \"fast\"])\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": 20,\n",
    "})\n",
    "\n",
    "funcs = '/Users/kjesta/Desktop/Masteremner/FYS-STK4155/Project_2_FYSSTK/Code'\n",
    "sys.path.append(os.path.abspath(funcs))\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591e9d9",
   "metadata": {},
   "source": [
    "Making the dataset, consiting of 1000 data points for 1-D Runge function with added stochastic noise. The noise has mean zero and standard deviation 0.1. the we split the data into training and testing sets, where the test set is 20% of the full data. We normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x = np.linspace(-1, 1, n)\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "y = runge_function(x) + np.random.normal(0, 0.1, (n,1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train_norm = (X_train - X_mean) / X_std\n",
    "X_test_norm  = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e9b15",
   "metadata": {},
   "source": [
    "To assess how network depth and width influence network performance, we train the network with different number of hidden layers and different number of nodes per layer. In addition to that, we see how different activation functions in the hidden layers impact the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_options = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "node_options = [2, 4, 8, 16, 32, 64]\n",
    "hidden_layers_options = [[n]*l for l in layer_options for n in node_options]  # different numbers of hidden layers and nodes\n",
    "activation_options = [sigmoid, RELU, LRELU]  # different activation functions for hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35115744",
   "metadata": {},
   "source": [
    "The neural network is trained with the above parameters and the results are stored in a Pandas dataframe. The metric used to assess performance is mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for layers in hidden_layers_options:\n",
    "    for activate in activation_options:\n",
    "\n",
    "        activation_funcs = [activate]*len(layers) + [identity]  # hidden + output\n",
    "        activation_ders  = [derivate(activate) for _ in layers] + [derivate(identity)]\n",
    "\n",
    "        # Initialize network\n",
    "        nn = NeuralNetwork(\n",
    "            network_input_size=X_train.shape[1],\n",
    "            layer_output_sizes=layers + [1],\n",
    "            activation_funcs=activation_funcs,\n",
    "            activation_ders=activation_ders,\n",
    "            cost_fun=mse,\n",
    "            cost_der=mse_der\n",
    "        )\n",
    "        \n",
    "        # Train network with stochastic gradient descent\n",
    "        nn.train_SGD(X_train, y_train, epochs=500, learning_rate=0.001)\n",
    "\n",
    "        y_pred_test = nn._feed_forward(X_test)\n",
    "        y_pred_train = nn._feed_forward(X_train)\n",
    "        \n",
    "        # Compute errors\n",
    "        train_err = mse(y_pred_train, y_train)\n",
    "        test_err  = mse(y_pred_test, y_test)\n",
    "        \n",
    "        results.append({\n",
    "            \"layers\": layers,\n",
    "            \"activation\": activate.__name__,\n",
    "            \"y_pred_test\": y_pred_test,\n",
    "            \"y_pred_train\": y_pred_train,\n",
    "            \"train_error\": train_err,\n",
    "            \"test_error\": test_err\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfbbe8",
   "metadata": {},
   "source": [
    "Plotting the MSE as a function of hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "for activate in df['activation'].unique():\n",
    "    subset = df[df['activation'] == activate]\n",
    "    ax.plot(subset['layers'].astype(str), subset['train_error'], marker='o', label=f'Train Error - {activate}')\n",
    "    ax.plot(subset['layers'].astype(str), subset['test_error'], marker='x', label=f'Test Error - {activate}')\n",
    "\n",
    "ax.set_xlabel(\"Hidden Layers\")\n",
    "ax.set_ylabel(\"Mean Squared Error\")\n",
    "ax.set_title(\"Neural Network Performance\")\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad073a",
   "metadata": {},
   "source": [
    "Sigmoid function, outputs between 0 and 1. \n",
    "* Useful for probabilisitic classification.\n",
    "* Can be computationally costly.\n",
    "* During training, the sigmoid function can cause gradients to become very small, which slows down learning, especially in deep networks.\n",
    "\n",
    "ReLU (Rectified Linear Unit), returns the input it recieves if the value is positive. Returns zero otherwise.\n",
    "* Fast to compute\n",
    "* Introduces nonlinearity\n",
    "* Mitigates vanishing gradient problem. If the input is positive, the gradient is a constant 1. Helps prevent gradients becoming too small during backpropagation and allows for faster learning.\n",
    "* If a neuron consistently receives negative inputs, it can get stuck in a state where it always outputs zero. Because the gradient is also zero, its weights are never updated, and the neuron becomes inactive (dies).\n",
    "\n",
    "LReLU (Leaky Rectified Linear Unit), also outputs the input if it is positive, but instead of zero for negative inputs it returns a small fraction. \n",
    "* Main purpose to prevent dying neurons.\n",
    "* Leads to more stable and consistent training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25251ac4",
   "metadata": {},
   "source": [
    "RELU and LRELU explodes for deep networks, so to see what is going on we zoom in on the y axis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "for activate in df['activation'].unique():\n",
    "    subset = df[df['activation'] == activate]\n",
    "    ax.plot(subset['layers'].astype(str), subset['train_error'], marker='o', label=f'Train Error - {activate}')\n",
    "    ax.plot(subset['layers'].astype(str), subset['test_error'], marker='x', label=f'Test Error - {activate}')\n",
    "\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "ax.set_xlabel(\"Hidden Layers\")\n",
    "ax.set_ylabel(\"Mean Squared Error\")\n",
    "ax.set_title(\"Neural Network Performance\")\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea94c9",
   "metadata": {},
   "source": [
    "* Diskuter, 3-gradspolynom ville vi forvente at OLS er bedre. Men Runge er vanskelig √• f√• til i endepunktene, s√• her er nok NN bedre enn OLS og andre klassiske regresjonsmetoder.\n",
    "* Dette er universal approksimasjonsteoreom i praksis. Vi vet vi kan approksimere til en viss feil, med minst et lag. Diskusjon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c387d",
   "metadata": {},
   "source": [
    "Now we plot heatmaps to better see the impact on MSE of the number of nodes and number of hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"n_hidden_layers\"] = df[\"layers\"].apply(len)\n",
    "df[\"n_nodes\"] = df[\"layers\"].apply(lambda x: x[0])\n",
    "\n",
    "activations = df['activation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a140d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(activations), figsize=(28, 10))\n",
    "\n",
    "for ax, act in zip(axes, activations):\n",
    "    subset = df[df[\"activation\"] == act]\n",
    "    heatmap_data = subset.pivot_table(\n",
    "        index=\"n_hidden_layers\",\n",
    "        columns=\"n_nodes\",\n",
    "        values=\"test_error\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt=\".4f\",\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Test MSE'},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{act} activation\")\n",
    "    ax.set_xlabel(\"Nodes per layer\")\n",
    "    ax.set_ylabel(\"Hidden layers\")\n",
    "\n",
    "fig.suptitle(\"Test Error Heatmaps by Activation Function\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(activations), figsize=(28, 10))\n",
    "\n",
    "for ax, act in zip(axes, activations):\n",
    "    subset = df[df[\"activation\"] == act]\n",
    "    heatmap_data = subset.pivot_table(\n",
    "        index=\"n_hidden_layers\",\n",
    "        columns=\"n_nodes\",\n",
    "        values=\"train_error\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt=\".4f\",\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Train MSE'},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{act} activation\")\n",
    "    ax.set_xlabel(\"Nodes per layer\")\n",
    "    ax.set_ylabel(\"Hidden layers\")\n",
    "\n",
    "fig.suptitle(\"Train Error Heatmaps by Activation Function\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sigmoid_test = df[df[\"activation\"] == \"sigmoid\"].sort_values(\"test_error\").iloc[0]\n",
    "best_RELU_test = df[df[\"activation\"] == \"RELU\"].sort_values(\"test_error\").iloc[0]\n",
    "best_LRELU_test = df[df[\"activation\"] == \"LRELU\"].sort_values(\"test_error\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sigmoid_train = df[df[\"activation\"] == \"sigmoid\"].sort_values(\"train_error\").iloc[0]\n",
    "best_RELU_train = df[df[\"activation\"] == \"RELU\"].sort_values(\"train_error\").iloc[0]\n",
    "best_LRELU_train = df[df[\"activation\"] == \"LRELU\"].sort_values(\"train_error\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Sigmoid Train:\", best_sigmoid_train)\n",
    "print()\n",
    "print(\"Best RELU Train:\", best_RELU_train)\n",
    "print()\n",
    "print(\"Best LRELU Train:\", best_LRELU_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebe816",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Sigmoid Test:\", best_sigmoid_test)\n",
    "print()\n",
    "print(\"Best RELU Test:\", best_RELU_test)\n",
    "print()\n",
    "print(\"Best LRELU Test:\", best_LRELU_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595f45b",
   "metadata": {},
   "source": [
    "* Sigmoid: tends to saturate (vanishing gradients), so performance often degreades with depth (number of hidden layers).\n",
    "* ReLU: Usually performs best for deeper networks due to non-saturating gradient.\n",
    "* Leaky ReLU: Often similar to ReLU but better for very deep networks (less dead neurons).\n",
    "\n",
    "* Increasing nodes/layers usually improves training performance but may increase overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf90c8",
   "metadata": {},
   "source": [
    "# Part e) Testing different norms\n",
    "\n",
    "Still using the one-dimensional Runge function, add now the hyperparameters $\\lambda$ with the $L_2$ and $L_1$ norms. Find the optimal results for the hyperparameters $\\lambda$ and the learning rates $\\eta$ and neural network architecture and compare the $L_2$ results with Ridge regression from project 1 and the $L_1$ results with the Lasso calculations of project 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af627ea4",
   "metadata": {},
   "source": [
    "To avoid crashing my computer I have chosen to work with the best architectures from part d) and use these to assess hyperparameter and learning rates with added norms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_architectures = {\n",
    "    \"sigmoid\": [64, 64, 64, 64, 64],\n",
    "    \"RELU\": [16, 16, 16],\n",
    "    \"LRELU\": [32, 32]\n",
    "}\n",
    "\n",
    "activation_funcs = {\n",
    "    \"sigmoid\": sigmoid,\n",
    "    \"RELU\": RELU,\n",
    "    \"LRELU\": LRELU\n",
    "}\n",
    "\n",
    "lambda_options = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "learning_rate_options = [0.001, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dadf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reg = []\n",
    "\n",
    "for act_name, layers in best_architectures.items():\n",
    "    for reg_type in [\"L1\",\"L2\"]:\n",
    "        for lamb in lambda_options:\n",
    "            for lr in learning_rate_options:\n",
    "                activate = activation_funcs[act_name]\n",
    "                \n",
    "                activation_funcs_list = [activate]*len(layers) + [identity]\n",
    "                activation_ders_list  = [derivate(activate) for _ in layers] + [derivate(identity)]\n",
    "                \n",
    "                nn = NeuralNetwork(\n",
    "                    network_input_size=X_train.shape[1],\n",
    "                    layer_output_sizes=layers + [1],\n",
    "                    activation_funcs=activation_funcs_list,\n",
    "                    activation_ders=activation_ders_list,\n",
    "                    cost_fun=mse,\n",
    "                    cost_der=mse_der,\n",
    "                    lamb=lamb,\n",
    "                    cost_fun_type=reg_type\n",
    "                )\n",
    "                \n",
    "                nn.train_SGD(X_train_norm, y_train, epochs=200, learning_rate=lr, batch_size=20)\n",
    "                \n",
    "                y_pred_test = nn._feed_forward(X_test_norm)\n",
    "                y_pred_train = nn._feed_forward(X_train_norm)\n",
    "                \n",
    "                results_reg.append({\n",
    "                    \"architecture\": act_name,\n",
    "                    \"layers\": layers,\n",
    "                    \"activation\": act_name,\n",
    "                    \"reg_type\": reg_type,\n",
    "                    \"lambda\": lamb,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"train_error\": mse(y_pred_train, y_train),\n",
    "                    \"test_error\": mse(y_pred_test, y_test)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.DataFrame(results_reg)\n",
    "\n",
    "# Best network for each combination\n",
    "best_L2 = df_reg[df_reg[\"reg_type\"]==\"L2\"].sort_values(\"test_error\").iloc[0]\n",
    "best_L1 = df_reg[df_reg[\"reg_type\"]==\"L1\"].sort_values(\"test_error\").iloc[0]\n",
    "\n",
    "print(\"Best L2 network:\")\n",
    "print(best_L2[[\"architecture\",\"layers\",\"lambda\",\"learning_rate\",\"train_error\",\"test_error\"]])\n",
    "\n",
    "print(\"Best L1 network:\")\n",
    "print(best_L1[[\"architecture\",\"layers\",\"lambda\",\"learning_rate\",\"train_error\",\"test_error\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2fb1b",
   "metadata": {},
   "source": [
    "**From project 1**\n",
    "\n",
    "Ridge/L2 regression:\n",
    "- The optimal $\\lambda$ was found to be smaller than $10^{-3}$.\n",
    "- Learning rate: ??\n",
    "\n",
    "Lasso/L1 regression:\n",
    "- The optimal $\\lambda$ was found to be ??\n",
    "- Learning rate??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae89260",
   "metadata": {},
   "source": [
    "Here‚Äôs a concise summary of the **Ridge** and **Lasso regression results** from your report (*Project1_FYSSTK.pdf*), focusing on their **hyperparameters**, **learning rates**, **best polynomial degree**, and **MSE performance**:\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ **Ridge Regression**\n",
    "\n",
    "### **Hyperparameter (Œª)**\n",
    "\n",
    "* Ridge regression includes an **L‚ÇÇ regularization** term controlled by **Œª**.\n",
    "* They tested Œª values from **10‚Åª¬π‚Å∞ up to 10¬π**.\n",
    "* **Optimal Œª ‚âà 1√ó10‚Åª‚Å¥**, found using **10-fold cross-validation**.\n",
    "* For **Œª < 10‚Åª¬≥**, Ridge‚Äôs MSE barely changed ‚Äî performance was stable at small regularization levels.\n",
    "* Larger Œª increased bias and test MSE by shrinking coefficients too strongly.\n",
    "\n",
    "### **Learning Rate (Œ∑)**\n",
    "\n",
    "* Ridge was **less sensitive** to learning rate compared to OLS and Lasso.\n",
    "* Converged well even for small Œ∑ (0.001‚Äì0.01).\n",
    "* Optimal performance found around **Œ∑ ‚âà 0.1** for gradient descent methods.\n",
    "* With adaptive optimizers (Adam/RMSProp), **Œ∑ = 0.1** gave the best convergence and lowest cost.\n",
    "\n",
    "### **Best Polynomial Degree & MSE**\n",
    "\n",
    "* **Best degree:** **12**\n",
    "* **Best Œª:** **1.0√ó10‚Åª‚Å¥**\n",
    "* **10-fold CV MSE:** **‚âà 0.0109**\n",
    "* Ridge performed similarly to OLS at low degrees and slightly worse at high degrees (due to coefficient shrinkage).\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ **Lasso Regression**\n",
    "\n",
    "### **Hyperparameter (Œª)**\n",
    "\n",
    "* Lasso uses an **L‚ÇÅ regularization** term that can zero out coefficients.\n",
    "* They scanned Œª across the same log range (10‚Åª‚Å¥ to 10‚Å∞).\n",
    "* **Optimal Œª ‚âà 1√ó10‚Åª‚Å¥**, also found from **10-fold CV**.\n",
    "* For larger Œª, MSE increased rapidly due to excessive shrinkage (over-penalization).\n",
    "\n",
    "### **Learning Rate (Œ∑)**\n",
    "\n",
    "* Sensitive to Œ∑; too large (‚â•0.2‚Äì0.3) caused unstable updates.\n",
    "* Best convergence and test MSE observed around **Œ∑ ‚âà 0.1**.\n",
    "* Like Ridge, adaptive methods (Adam, RMSProp) worked well, with **Adam + Œ∑ = 0.1** giving the smoothest convergence.\n",
    "\n",
    "### **Best Polynomial Degree & MSE**\n",
    "\n",
    "* **Best degree:** **8**\n",
    "* **Best Œª:** **1.0√ó10‚Åª‚Å¥**\n",
    "* **10-fold CV MSE:** **‚âà 0.0143**\n",
    "\n",
    "Lasso favored simpler models ‚Äî its L‚ÇÅ penalty pruned higher-order coefficients, reducing variance but increasing bias slightly compared to Ridge and OLS.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Overall Comparison**\n",
    "\n",
    "| Method    | Best Degree | Best Œª | Optimal Œ∑ | 10-fold CV MSE | Notes                        |\n",
    "| :-------- | :---------: | :----: | :-------: | :------------: | :--------------------------- |\n",
    "| **Ridge** |      12     | 1√ó10‚Åª‚Å¥ |    ~0.1   |   **0.0109**   | Stable; less sensitive to Œ∑  |\n",
    "| **Lasso** |      8      | 1√ó10‚Åª‚Å¥ |    ~0.1   |   **0.0143**   | More bias; promotes sparsity |\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Insight:**\n",
    "\n",
    "* Both Ridge and Lasso preferred **small regularization (Œª ‚âà 10‚Åª‚Å¥)**.\n",
    "* **Œ∑ ‚âà 0.1** gave the best learning performance across optimizers.\n",
    "* Ridge achieved **lower MSE** and handled higher polynomial degrees better, while Lasso preferred simpler models and higher bias for smoother fits.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
