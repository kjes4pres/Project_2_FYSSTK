{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2ab151",
   "metadata": {},
   "source": [
    "# Part a) Analytical warm-up\n",
    "\n",
    "When using our gradient machinery from project 1, we will need the expressions for the cost/loss functions and their respective gradients. The functions whose gradients we need are:\n",
    "\n",
    "1. The mean-squared error (MSE) with and without the and norms (regression problems)\n",
    "2. The binary cross entropy (aka log loss) for binary classification problems with and without and norms\n",
    "3. The multiclass cross entropy cost/loss function (aka Softmax cross entropy or just Softmax loss function)\n",
    "\n",
    "Set up these three cost/loss functions and their respective derivatives and explain the various terms. In this project you will however only use the MSE and the Softmax cross entropy.\n",
    "\n",
    "We will test three activation functions for our neural network setup, these are the\n",
    "\n",
    "1. The Sigmoid (aka logit) function,\n",
    "2. the RELU function and\n",
    "3. the Leaky RELU function\n",
    "\n",
    "Set up their expressions and their first derivatives. You may consult the lecture notes (with codes and more) from week 42 at https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/week42.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec03dfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Neural networks basics\n",
    "\n",
    "$$\\boldsymbol{z^l = W^l \\cdot a^{l-1} + b^l}$$\n",
    "$$ \\boldsymbol{a^l} = \\sigma(\\boldsymbol{z^l})$$\n",
    "\n",
    "Where $l$ denotes the layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d09db5",
   "metadata": {},
   "source": [
    "## Activation functions and their derivatives\n",
    "\n",
    "### Sigmoid function\n",
    "\n",
    "$$\\sigma(\\boldsymbol{z^l}) = \\frac{1}{1 + e^{-\\boldsymbol{z^l}}}$$\n",
    "\n",
    "$$\\frac{d \\sigma }{d \\boldsymbol{z^l}} = \\sigma(\\boldsymbol{z^l}) ' \\cdot (1 - \\sigma(\\boldsymbol{z^l})$$\n",
    "\n",
    "### ReLU function\n",
    "\n",
    "$$$$\n",
    "\n",
    "### Leaky ReLU function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfefe5",
   "metadata": {},
   "source": [
    "# MSE as cost function and its derivatives\n",
    "\n",
    "$$\\text{MSE} = \\boldsymbol{C(\\theta)} = \\frac{1}{2}(\\boldsymbol{a^l - y})^2,$$\n",
    "\n",
    "where $\\boldsymbol{a^l}$ is the output of layer $l$, and $\\boldsymbol{y}$ is the target value. $\\boldsymbol{a^l}$ and the cost function is thus dependent on the specific activation function of the layer, and the parameters $\\boldsymbol{\\theta = (W, b)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7719c8ad",
   "metadata": {},
   "source": [
    "To find the derivative, we use the chain rule. \n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{W}} = \\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a}}\\frac{\\partial \\boldsymbol{a}}{\\partial \\boldsymbol{z}}\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{W}}$$\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{b}} = \\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a}}\\frac{\\partial \\boldsymbol{a}}{\\partial \\boldsymbol{z}}\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2f905",
   "metadata": {},
   "source": [
    "### Using the Sigmoid activation function\n",
    "We can do this step by step and gather the terms in the end. The sigmoid function is: $$\\boldsymbol{a^l} = \\sigma(\\boldsymbol{z^l}) = \\frac{1}{1 + e^{-\\boldsymbol{z^l}}}$$\n",
    "\n",
    "#### $\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{W}}:$\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a^l}} = \\frac{\\partial}{\\partial \\boldsymbol{a^l}} (\\frac{1}{2}(\\boldsymbol{a^l - y})^2) = (\\boldsymbol{a^l - y})$$\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{a^l}}{\\partial \\boldsymbol{z^l}} = \\frac{\\partial \\sigma(\\boldsymbol{z^l})}{\\partial \\boldsymbol{z^l}} = \\frac{\\partial}{\\partial \\boldsymbol{z^l}}(\\frac{1}{1 + e^{-\\boldsymbol{z^l}}}) = \\sigma(\\boldsymbol{z^l}) \\cdot (1 - \\sigma(\\boldsymbol{z^l})) = \\boldsymbol{a^l} \\cdot (1 - \\boldsymbol{a^l})$$\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{z^l}}{\\partial \\boldsymbol{W^l}} = \\frac{\\partial}{\\partial \\boldsymbol{W^l}}(\\boldsymbol{W^l \\cdot a^{l-1} + b^l}) = \\boldsymbol{a^{l-1}}$$\n",
    "\n",
    "Gathering the terms yield:\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{W^l}} = (\\boldsymbol{a^l - y}) \\boldsymbol{a^l} \\cdot (1 - \\boldsymbol{a^l}) \\boldsymbol{a^{l-1}}$$\n",
    "\n",
    "By defining $\\delta^l = (\\boldsymbol{a^l - y}) \\boldsymbol{a^l} \\cdot (1 - \\boldsymbol{a^l}) = \\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a^l}} \\sigma'$, we have the final expression for the gradient of the cost function with respect to the weights, using MSE and Sigmoid, as:\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{W^l}} = \\delta^l \\cdot \\boldsymbol{a^{l-1}}$$\n",
    "\n",
    "#### $\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{b}}:$\n",
    "\n",
    "For the gradient with respect to the bias we can reuse expressions for $\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a}}$ and $\\frac{\\partial \\boldsymbol{a}}{\\partial \\boldsymbol{z}}$.\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{b}}=1$$\n",
    "\n",
    "So the gradient is simply:\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{b^l}} = \\delta^l$$\n",
    "\n",
    "**MSE cost function derivatives with Sigmoid function**\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{W^l}} = \\delta^l \\cdot \\boldsymbol{a^{l-1}}$$\n",
    "\n",
    "$$\\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{b^l}} = \\delta^l$$\n",
    "\n",
    "$$\\delta^l = \\frac{\\partial \\boldsymbol{C}}{\\partial \\boldsymbol{a^l}} \\sigma ' $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a99192",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
