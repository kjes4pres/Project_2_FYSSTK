{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acf87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c14f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_oh  = encoder.transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7855b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 done. Train accuracy: 0.3908. Test accuracy: 0.3927\n",
      "Model 2 done. Train accuracy: 0.4491. Test accuracy: 0.4423\n",
      "Model 3 done. Train accuracy: 0.3653. Test accuracy: 0.3603\n",
      "Model 4 done. Train accuracy: 0.6334. Test accuracy: 0.6319\n",
      "Model 5 done. Train accuracy: 0.8146. Test accuracy: 0.8013\n",
      "Model 6 done. Train accuracy: 0.7817. Test accuracy: 0.7691\n",
      "Model 7 done. Train accuracy: 0.8189. Test accuracy: 0.8206\n",
      "Model 8 done. Train accuracy: 0.9160. Test accuracy: 0.8971\n",
      "Model 9 done. Train accuracy: 0.8788. Test accuracy: 0.8714\n",
      "Model 10 done. Train accuracy: 0.8932. Test accuracy: 0.8873\n",
      "Model 11 done. Train accuracy: 0.9562. Test accuracy: 0.9318\n",
      "Model 12 done. Train accuracy: 0.9400. Test accuracy: 0.9173\n",
      "Model 13 done. Train accuracy: 0.9286. Test accuracy: 0.9210\n",
      "Model 14 done. Train accuracy: 0.9827. Test accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uio/hume/student-u15/sverremj/Master/Project_2_FYSSTK/Project_2_FYSSTK/Code/functions/activation_funcs.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 15 done. Train accuracy: 0.9681. Test accuracy: 0.9461\n",
      "Model 16 done. Train accuracy: 0.9460. Test accuracy: 0.9273\n",
      "Model 17 done. Train accuracy: 0.9969. Test accuracy: 0.9588\n",
      "Model 18 done. Train accuracy: 0.9699. Test accuracy: 0.9487\n",
      "Model 19 done. Train accuracy: 0.9655. Test accuracy: 0.9343\n",
      "Model 20 done. Train accuracy: 0.9999. Test accuracy: 0.9649\n",
      "Model 21 done. Train accuracy: 0.9752. Test accuracy: 0.9584\n",
      "Model 22 done. Train accuracy: 0.3559. Test accuracy: 0.3616\n",
      "Model 23 done. Train accuracy: 0.4042. Test accuracy: 0.4003\n",
      "Model 24 done. Train accuracy: 0.3858. Test accuracy: 0.3855\n",
      "Model 25 done. Train accuracy: 0.4695. Test accuracy: 0.4739\n",
      "Model 26 done. Train accuracy: 0.8074. Test accuracy: 0.7929\n",
      "Model 27 done. Train accuracy: 0.6774. Test accuracy: 0.6678\n",
      "Model 28 done. Train accuracy: 0.8218. Test accuracy: 0.8159\n",
      "Model 29 done. Train accuracy: 0.9105. Test accuracy: 0.8901\n",
      "Model 30 done. Train accuracy: 0.8946. Test accuracy: 0.8839\n",
      "Model 31 done. Train accuracy: 0.8968. Test accuracy: 0.8923\n",
      "Model 32 done. Train accuracy: 0.9597. Test accuracy: 0.9321\n",
      "Model 33 done. Train accuracy: 0.9428. Test accuracy: 0.9268\n",
      "Model 34 done. Train accuracy: 0.9283. Test accuracy: 0.9151\n",
      "Model 35 done. Train accuracy: 0.9861. Test accuracy: 0.9487\n",
      "Model 36 done. Train accuracy: 0.9521. Test accuracy: 0.9349\n",
      "Model 37 done. Train accuracy: 0.9544. Test accuracy: 0.9300\n",
      "Model 38 done. Train accuracy: 0.9984. Test accuracy: 0.9564\n",
      "Model 39 done. Train accuracy: 0.9584. Test accuracy: 0.9433\n",
      "Model 40 done. Train accuracy: 0.9777. Test accuracy: 0.9336\n",
      "Model 41 done. Train accuracy: 0.9992. Test accuracy: 0.9632\n",
      "Model 42 done. Train accuracy: 0.9553. Test accuracy: 0.9429\n",
      "Model 43 done. Train accuracy: 0.2119. Test accuracy: 0.2071\n",
      "Model 44 done. Train accuracy: 0.3062. Test accuracy: 0.3004\n",
      "Model 45 done. Train accuracy: 0.2753. Test accuracy: 0.2813\n",
      "Model 46 done. Train accuracy: 0.3957. Test accuracy: 0.3971\n",
      "Model 47 done. Train accuracy: 0.7558. Test accuracy: 0.7366\n",
      "Model 48 done. Train accuracy: 0.7137. Test accuracy: 0.7091\n",
      "Model 49 done. Train accuracy: 0.8273. Test accuracy: 0.8212\n",
      "Model 50 done. Train accuracy: 0.9273. Test accuracy: 0.9039\n",
      "Model 51 done. Train accuracy: 0.8991. Test accuracy: 0.8846\n",
      "Model 52 done. Train accuracy: 0.8813. Test accuracy: 0.8785\n",
      "Model 53 done. Train accuracy: 0.9623. Test accuracy: 0.9365\n",
      "Model 54 done. Train accuracy: 0.9351. Test accuracy: 0.9220\n",
      "Model 55 done. Train accuracy: 0.9316. Test accuracy: 0.9185\n",
      "Model 56 done. Train accuracy: 0.9844. Test accuracy: 0.9476\n",
      "Model 57 done. Train accuracy: 0.9493. Test accuracy: 0.9391\n",
      "Model 58 done. Train accuracy: 0.9558. Test accuracy: 0.9236\n",
      "Model 59 done. Train accuracy: 0.9974. Test accuracy: 0.9536\n",
      "Model 60 done. Train accuracy: 0.9482. Test accuracy: 0.9370\n",
      "Model 61 done. Train accuracy: 0.9816. Test accuracy: 0.9311\n",
      "Model 62 done. Train accuracy: 0.9972. Test accuracy: 0.9594\n",
      "Model 63 done. Train accuracy: 0.4007. Test accuracy: 0.4014\n",
      "Model 64 done. Train accuracy: 0.2081. Test accuracy: 0.2116\n",
      "Model 65 done. Train accuracy: 0.3078. Test accuracy: 0.3042\n",
      "Model 66 done. Train accuracy: 0.1002. Test accuracy: 0.0986\n",
      "Model 67 done. Train accuracy: 0.3635. Test accuracy: 0.3666\n",
      "Model 68 done. Train accuracy: 0.4864. Test accuracy: 0.4781\n",
      "Model 69 done. Train accuracy: 0.4750. Test accuracy: 0.4724\n",
      "Model 70 done. Train accuracy: 0.6774. Test accuracy: 0.6722\n",
      "Model 71 done. Train accuracy: 0.9041. Test accuracy: 0.8885\n",
      "Model 72 done. Train accuracy: 0.7525. Test accuracy: 0.7486\n",
      "Model 73 done. Train accuracy: 0.8906. Test accuracy: 0.8806\n",
      "Model 74 done. Train accuracy: 0.9586. Test accuracy: 0.9340\n",
      "Model 75 done. Train accuracy: 0.9118. Test accuracy: 0.9006\n",
      "Model 76 done. Train accuracy: 0.9312. Test accuracy: 0.9149\n",
      "Model 77 done. Train accuracy: 0.9843. Test accuracy: 0.9462\n",
      "Model 78 done. Train accuracy: 0.9427. Test accuracy: 0.9319\n",
      "Model 79 done. Train accuracy: 0.9558. Test accuracy: 0.9279\n",
      "Model 80 done. Train accuracy: 0.9952. Test accuracy: 0.9526\n",
      "Model 81 done. Train accuracy: 0.9318. Test accuracy: 0.9211\n",
      "Model 82 done. Train accuracy: 0.9844. Test accuracy: 0.9264\n",
      "Model 83 done. Train accuracy: 0.9935. Test accuracy: 0.9593\n",
      "Model 84 done. Train accuracy: 0.0987. Test accuracy: 0.0925\n"
     ]
    }
   ],
   "source": [
    "depth = [1,2,3,4]\n",
    "width = [2, 4, 8, 16, 32, 64, 128]\n",
    "lr = [0.001, 0.01, 0.1]\n",
    "information = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [sigmoid]*d + [softmax], [derivate(sigmoid)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information['depth'].append(d)\n",
    "            information['width'].append(w)\n",
    "            information['lr'].append(r)\n",
    "            information['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38912386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 done. Train accuracy: 0.3529. Test accuracy: 0.3449\n",
      "Model 2 done. Train accuracy: 0.6809. Test accuracy: 0.6709\n",
      "Model 3 done. Train accuracy: 0.4081. Test accuracy: 0.4063\n",
      "Model 4 done. Train accuracy: 0.5699. Test accuracy: 0.5675\n",
      "Model 5 done. Train accuracy: 0.6759. Test accuracy: 0.6787\n",
      "Model 6 done. Train accuracy: 0.6618. Test accuracy: 0.6499\n",
      "Model 7 done. Train accuracy: 0.6192. Test accuracy: 0.6213\n",
      "Model 8 done. Train accuracy: 0.9131. Test accuracy: 0.9026\n",
      "Model 9 done. Train accuracy: 0.6830. Test accuracy: 0.6770\n",
      "Model 10 done. Train accuracy: 0.8533. Test accuracy: 0.8532\n",
      "Model 11 done. Train accuracy: 0.9580. Test accuracy: 0.9406\n",
      "Model 12 done. Train accuracy: 0.9143. Test accuracy: 0.8998\n",
      "Model 13 done. Train accuracy: 0.9151. Test accuracy: 0.9033\n",
      "Model 14 done. Train accuracy: 0.9823. Test accuracy: 0.9537\n"
     ]
    }
   ],
   "source": [
    "information_Relu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [RELU]*d + [softmax], [derivate(RELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_Relu['depth'].append(d)\n",
    "            information_Relu['width'].append(w)\n",
    "            information_Relu['lr'].append(r)\n",
    "            information_Relu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_lRelu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [LRELU]*d + [softmax], [derivate(LRELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_lRelu['depth'].append(d)\n",
    "            information_lRelu['width'].append(w)\n",
    "            information_lRelu['lr'].append(r)\n",
    "            information_lRelu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_sig = pd.DataFrame(information)\n",
    "df_sig[['train_acc', 'test_acc']] = pd.DataFrame(df_sig['acc'].tolist(), index=df_sig.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_sig.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d01598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_relu = pd.DataFrame(information_Relu)\n",
    "df_relu[['train_acc', 'test_acc']] = pd.DataFrame(df_relu['acc'].tolist(), index=df_relu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_relu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_lrelu = pd.DataFrame(information_lRelu)\n",
    "df_lrelu[['train_acc', 'test_acc']] = pd.DataFrame(df_lrelu['acc'].tolist(), index=df_lrelu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_lrelu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996375 0.9699285714285715\n"
     ]
    }
   ],
   "source": [
    "reg_type = ['L1', 'L2']\n",
    "lamb = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "for i in reg_type:\n",
    "    for j in lamb:\n",
    "        Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type=i)\n",
    "        Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "        y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "        y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "        y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "        y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "        train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "        test_accuracy = np.mean(y_test == y_pred_label)\n",
    "        print(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lamb = [2e-2, 3e-2, 4e-2, 5e-2]\n",
    "for i in reg_type:\n",
    "    for j in lamb:\n",
    "        Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type='L2')\n",
    "        Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "        y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "        y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "        y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "        y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "        train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "        test_accuracy = np.mean(y_test == y_pred_label)\n",
    "        print(train_accuracy, test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
