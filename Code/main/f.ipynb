{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "  \n",
    "from functions import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# For saving figures\n",
    "out_dir = Path(\"../../Figures\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_oh  = encoder.transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [1,2,3,4]\n",
    "width = [2, 4, 8, 16, 32, 64, 128]\n",
    "lr = [0.001, 0.01, 0.1]\n",
    "information = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [sigmoid]*d + [softmax], [derivate(sigmoid)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information['depth'].append(d)\n",
    "            information['width'].append(w)\n",
    "            information['lr'].append(r)\n",
    "            information['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38912386",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_Relu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [RELU]*d + [softmax], [derivate(RELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_Relu['depth'].append(d)\n",
    "            information_Relu['width'].append(w)\n",
    "            information_Relu['lr'].append(r)\n",
    "            information_Relu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_lRelu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [LRELU]*d + [softmax], [derivate(LRELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_lRelu['depth'].append(d)\n",
    "            information_lRelu['width'].append(w)\n",
    "            information_lRelu['lr'].append(r)\n",
    "            information_lRelu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_sig = pd.DataFrame(information)\n",
    "df_sig[['train_acc', 'test_acc']] = pd.DataFrame(df_sig['acc'].tolist(), index=df_sig.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_sig.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.ylabel(\"Depth (# layers)\")\n",
    "plt.xlabel(\"Width (# neurons)\")\n",
    "plt.savefig(out_dir / \"heatmap_sigmoid_class.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d01598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_relu = pd.DataFrame(information_Relu)\n",
    "df_relu[['train_acc', 'test_acc']] = pd.DataFrame(df_relu['acc'].tolist(), index=df_relu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_relu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.ylabel(\"Depth (# layers)\")\n",
    "plt.xlabel(\"Width (# neurons)\")\n",
    "plt.savefig(out_dir / \"heatmap_relu_class.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_lrelu = pd.DataFrame(information_lRelu)\n",
    "df_lrelu[['train_acc', 'test_acc']] = pd.DataFrame(df_lrelu['acc'].tolist(), index=df_lrelu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_lrelu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.ylabel(\"Depth (# layers)\")\n",
    "plt.xlabel(\"Width (# neurons)\")\n",
    "plt.savefig(out_dir / \"heatmap_lrelu_class.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_type = ['L1', 'L2']\n",
    "lamb = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "mses_reg = []\n",
    "for i in reg_type:\n",
    "    for j in lamb:\n",
    "        class_nn_reg = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type=i)\n",
    "        class_nn_reg.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.001, optimizer='Adam')\n",
    "        y_pred_train = class_nn_reg._feed_forward(X_train)\n",
    "        y_pred_test = class_nn_reg._feed_forward(X_test)\n",
    "        y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "        y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "    \n",
    "        train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "        test_accuracy = np.mean(y_test == y_pred_label)\n",
    "        mses_reg.append((train_accuracy, test_accuracy))\n",
    "        print(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bacdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dict = {\n",
    "    'reg_type': ['L1']*len(lamb) + ['L2']*len(lamb),\n",
    "    'lamb': lamb * 2,\n",
    "    'train_acc': [acc[0] for acc in mses_reg],\n",
    "    'test_acc': [acc[1] for acc in mses_reg]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.DataFrame(reg_dict)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.lineplot(data=df_reg, x='lamb', y='train_acc', hue='reg_type', marker='o', ax=ax, linewidth=3.2)\n",
    "sns.lineplot(data=df_reg, x='lamb', y='test_acc', hue='reg_type', marker='o', ax=ax, linestyle='--', linewidth=3.2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_title('Effect of Regularization on Training and Test Accuracy', size=16)\n",
    "ax.set_xlabel('Regularization Parameter (lambda)', size=14)\n",
    "ax.set_ylabel('Accuracy', size=14)\n",
    "plt.savefig(out_dir / \"regularization_effect_class.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lamb = [2e-2, 3e-2, 4e-2, 5e-2]\n",
    "\n",
    "for j in lamb:\n",
    "    Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type='L2')\n",
    "    Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "    y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "    y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "    y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "    y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "    train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "    test_accuracy = np.mean(y_test == y_pred_label)\n",
    "    print(train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "scipy.interp = np.interp\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42162c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=3e-2, cost_fun_type='L2')\n",
    "Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "y_pred_label = np.argmax(y_pred_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test, y_pred_label, normalize=False, figsize=(9,6))\n",
    "plt.savefig(out_dir / \"confusion_matrix_class.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e872c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = np.unique_counts(y_test)[1]\n",
    "preds = np.unique_counts(y_pred_label)[1]\n",
    "TP = [1311, 1577, 1316, 1370, 1255, 1214, 1368, 1462, 1272, 1359]\n",
    "FN = uni - TP\n",
    "FP = preds - TP\n",
    "TN = len(y_test) - (TP + FP + FN)\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
