{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c14f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_oh  = encoder.transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855b2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m width:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m lr:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         Reg_nn = \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m,\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mderivate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderivate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_entropy_der\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         Reg_nn.train_SGD(X_train, y_train_oh, epochs=\u001b[32m100\u001b[39m, batch_size=\u001b[32m1000\u001b[39m, learning_rate=r, optimizer=\u001b[33m\"\u001b[39m\u001b[33mAdam\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m         y_pred = Reg_nn._feed_forward(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Master/Project_2_FYSSTK/Project_2_FYSSTK/Code/functions/ffnn.py:25\u001b[39m, in \u001b[36mNeuralNetwork.__init__\u001b[39m\u001b[34m(self, network_input_size, layer_output_sizes, activation_funcs, activation_ders, cost_fun, cost_der, lamb, cost_fun_type)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.layer_output_sizes = layer_output_sizes\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.network_input_size = network_input_size\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28mself\u001b[39m.weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_input_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mself\u001b[39m.lamb = lamb\n\u001b[32m     27\u001b[39m \u001b[38;5;28mself\u001b[39m.cost_fun_type = cost_fun_type\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Master/Project_2_FYSSTK/Project_2_FYSSTK/Code/functions/ffnn.py:54\u001b[39m, in \u001b[36mNeuralNetwork.create_layers\u001b[39m\u001b[34m(self, network_input_size, layer_output_sizes, seed)\u001b[39m\n\u001b[32m     52\u001b[39m i_size = network_input_size\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_output_size \u001b[38;5;129;01min\u001b[39;00m layer_output_sizes:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     W = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_output_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     b = np.random.randn(layer_output_size, )\n\u001b[32m     56\u001b[39m     layers.append((W, b))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/exercises/lib/python3.13/site-packages/autograd/tracer.py:54\u001b[39m, in \u001b[36mprimitive.<locals>.f_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:1306\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.randn\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:1466\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.standard_normal\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_common.pyx:655\u001b[39m, in \u001b[36mnumpy.random._common.cont\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "depth = [1,2,3,4]\n",
    "width = [2, 4, 8, 16, 32, 64, 128]\n",
    "lr = [0.001, 0.01, 0.1]\n",
    "information = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [sigmoid]*d + [softmax], [derivate(sigmoid)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information['depth'].append(d)\n",
    "            information['width'].append(w)\n",
    "            information['lr'].append(r)\n",
    "            information['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38912386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "information_Relu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [RELU]*d + [softmax], [derivate(RELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_Relu['depth'].append(d)\n",
    "            information_Relu['width'].append(w)\n",
    "            information_Relu['lr'].append(r)\n",
    "            information_Relu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_lRelu = {\n",
    "    'depth' : [],\n",
    "    'width' : [],\n",
    "    'lr' : [],\n",
    "\n",
    "    'acc' : []\n",
    "}\n",
    "\n",
    "\n",
    "Model = 1\n",
    "for d in depth:\n",
    "    for w in width:\n",
    "        for r in lr:\n",
    "            Reg_nn = NeuralNetwork(X_train.shape[1], [w]*d + [10], [LRELU]*d + [softmax], [derivate(LRELU)]*d + [derivate(softmax)], cross_entropy, cross_entropy_der)\n",
    "            Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=r, optimizer=\"Adam\")\n",
    "            y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "            y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "            y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "            y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "            train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "            test_accuracy = np.mean(y_test == y_pred_label)\n",
    "\n",
    "            information_lRelu['depth'].append(d)\n",
    "            information_lRelu['width'].append(w)\n",
    "            information_lRelu['lr'].append(r)\n",
    "            information_lRelu['acc'].append((train_accuracy,test_accuracy))\n",
    "              \n",
    "\n",
    "            print(f\"Model {Model} done. Train accuracy: {train_accuracy:.4f}. Test accuracy: {test_accuracy:.4f}\")\n",
    "            Model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_sig = pd.DataFrame(information)\n",
    "df_sig[['train_acc', 'test_acc']] = pd.DataFrame(df_sig['acc'].tolist(), index=df_sig.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_sig.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d01598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_relu = pd.DataFrame(information_Relu)\n",
    "df_relu[['train_acc', 'test_acc']] = pd.DataFrame(df_relu['acc'].tolist(), index=df_relu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_relu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to DataFrame\n",
    "df_lrelu = pd.DataFrame(information_lRelu)\n",
    "df_lrelu[['train_acc', 'test_acc']] = pd.DataFrame(df_lrelu['acc'].tolist(), index=df_lrelu.index)\n",
    "\n",
    "# Compute mean accuracy across learning rates for each depth–width pair\n",
    "df_sig_grouped = df_lrelu.groupby(['depth', 'width'], as_index=False)['train_acc'].mean()\n",
    "\n",
    "# Pivot into matrix form for heatmap\n",
    "heatmap_data = df_sig_grouped.pivot(index='depth', columns='width', values='train_acc')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Mean Accuracy Heatmap for sigmoid (averaged over learning rates)\")\n",
    "plt.xlabel(\"Depth (# layers)\")\n",
    "plt.ylabel(\"Width (# neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aa660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996375 0.9699285714285715\n"
     ]
    }
   ],
   "source": [
    "reg_type = ['L1', 'L2']\n",
    "lamb = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "for i in reg_type:\n",
    "    for j in lamb:\n",
    "        Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type=i)\n",
    "        Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "        y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "        y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "        y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "        y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "        train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "        test_accuracy = np.mean(y_test == y_pred_label)\n",
    "        print(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lamb = [2e-2, 3e-2, 4e-2, 5e-2]\n",
    "for i in reg_type:\n",
    "    for j in lamb:\n",
    "        Reg_nn = NeuralNetwork(X_train.shape[1], [128,10], [sigmoid,  softmax], [derivate(sigmoid), derivate(softmax)], cross_entropy, cross_entropy_der, lamb=j, cost_fun_type='L2')\n",
    "        Reg_nn.train_SGD(X_train, y_train_oh, epochs=30, batch_size=1000, learning_rate=0.01, optimizer='Adam')\n",
    "        y_pred_train = Reg_nn._feed_forward(X_train)\n",
    "        y_pred_test = Reg_nn._feed_forward(X_test)\n",
    "        y_pred_label_train = np.argmax(y_pred_train, axis=1)\n",
    "        y_pred_label = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "        train_accuracy = np.mean(y_train == y_pred_label_train)\n",
    "        test_accuracy = np.mean(y_test == y_pred_label)\n",
    "        print(train_accuracy, test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
